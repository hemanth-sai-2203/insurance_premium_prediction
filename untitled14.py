# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jznJ0PdVDPAC072urJwIQBYPU2Tuh3HY

### Importing core libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import statsmodels.api as sm
from xgboost import XGBRegressor
from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeRegressor
import joblib
from sklearn.model_selection import cross_val_score

"""### Importing data"""

df = pd.read_csv("insurance_data.csv")
df.head()

df.describe()

df.info()

"""### Check for Missing Values"""

print(df.isnull().sum())

df.fillna({
    'bmi': df['bmi'].median(),
    'children': df['children'].median(),
    'sex': df['sex'].mode()[0],
    'smoker': df['smoker'].mode()[0],
    'region': df['region'].mode()[0]
}, inplace=True)

"""### Encode Categorical Columns"""

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

categorical_cols = ['sex', 'smoker', 'region']
numeric_cols = ['age', 'bmi', 'children']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', 'passthrough', numeric_cols),
        ('cat', OneHotEncoder(drop='first'), categorical_cols)
    ]
)

"""### Split Features and Target And then train-test split"""

X = df.drop('expenses', axis=1)
y = df['expenses']
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
feature_names = X.columns

"""### Scaling (Optional but Recommended)"""

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

scaler = StandardScaler()

from sklearn.linear_model import LinearRegression

model_pipeline = Pipeline(steps=[
    ('preprocess', ColumnTransformer([
        ('num', StandardScaler(), numeric_cols),
        ('cat', OneHotEncoder(drop='first'), categorical_cols)
    ])),
    ('model', LinearRegression())
])

model_pipeline.fit(X_train, y_train)

"""### Verify Transformation"""

X_train_transformed = model_pipeline.named_steps['preprocess'].transform(X_train)
print(X_train_transformed.shape)

"""### Univariate Analysis
####a) Numeric Columns - Histograms
"""

numeric_cols = ['age', 'bmi', 'children', 'expenses']

for col in numeric_cols:
    plt.figure()
    sns.histplot(df[col], kde=True, bins=30)
    plt.title(f"Distribution of {col}")
    plt.xlabel(col)
    plt.ylabel("Count")
    plt.show()

"""#### b) Categorical Columns - Count Plots"""

categorical_cols = ['sex', 'smoker', 'region']

for col in categorical_cols:
    plt.figure()
    sns.countplot(x=col, data=df, palette="Set2")
    plt.title(f"Count Plot of {col}")
    plt.ylabel("Count")
    plt.show()

"""### 3. Bivariate Analysis"""

# Set seaborn style
sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (8,5)

# a) Expenses vs Categorical Variables

for col in categorical_cols:
    plt.figure()
    sns.boxplot(x=col, y="expenses", data=df, palette="Set3")
    plt.title(f"Expenses by {col}")
    plt.ylabel("Expenses")
    plt.show()

#b) Expenses vs BMI Scatter Plot

plt.figure()
sns.scatterplot(x="bmi", y="expenses", hue="smoker", data=df, palette="coolwarm")
plt.title("Expenses vs BMI (colored by Smoker)")
plt.xlabel("BMI")
plt.ylabel("Expenses")
plt.show()

"""### Correlation Heatmap"""

plt.figure(figsize=(8,6))
corr = df[numeric_cols].corr()
sns.heatmap(corr, annot=True, cmap="Blues", fmt=".2f")
plt.title("Correlation Heatmap - Numeric Features")
plt.show()

"""### Outlier detection"""

for col in ["bmi", "expenses"]:
    plt.figure()
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot of {col}")
    plt.show()

"""### Define Model"""

models = {
    "LinearRegression": LinearRegression(),
    "DecisionTree": DecisionTreeRegressor(random_state=42),
    "RandomForest": RandomForestRegressor(n_estimators=100, random_state=42),
    "GradientBoosting": GradientBoostingRegressor(n_estimators=100, random_state=42),
    "SVR": SVR(kernel='rbf')
}

"""### Train & Evaluate Models"""

results = []

for name, model in models.items():
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', model)
    ])

    pipeline.fit(X_train, y_train)

    y_pred = pipeline.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    results.append({
        'Model': name,
        'MAE': round(mae, 2),
        'RMSE': round(rmse, 2),
        'R2 Score': round(r2, 4)
    })

    joblib.dump(pipeline, f"{name}_insurance_model.pkl")

results_df = pd.DataFrame(results)
print(results_df)

"""### pick the best model"""

best_model_name = results_df.loc[results_df['R2 Score'].idxmax(), 'Model']
print(f"Best Model: {best_model_name}")

"""### cross validation"""

for name, model in models.items():
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', model)
    ])
    scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')
    print(f"{name} Cross-Validated R2: {scores.mean():.4f} (+/- {scores.std():.4f})")

"""### hyperparameter tuning"""

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('model', GradientBoostingRegressor(random_state=42))
])

param_grid = {
    'model__n_estimators': [100, 200],
    'model__learning_rate': [0.05, 0.1],
    'model__max_depth': [3, 4],
    'model__subsample': [1.0],
    'model__min_samples_split': [2, 5],
    'model__min_samples_leaf': [1, 2]
}

grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=2
)

grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
print("Best CV R2 Score:", grid_search.best_score_)

best_gb_model = grid_search.best_estimator_
test_r2 = best_gb_model.score(X_test, y_test)
print("Test R2 Score:", test_r2)

joblib.dump(best_gb_model, "GradientBoosting_Best_Model.pkl")

